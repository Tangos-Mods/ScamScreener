# AI System (Developer Explanation)

In this project, the AI layer is a local scoring component inside the detection pipeline, positioned after rule, similarity, behavior, trend, and funnel signal generation. Its job is not to replace those deterministic stages, but to turn all accumulated context into probabilistic risk signals that can capture patterns that are hard to express with a single rule.

The runtime AI architecture is a lightweight logistic-style model with two related heads. The main head produces a general risk signal, and a dedicated funnel head focuses on conversation-structure risk. Both heads operate on the same behavioral context object, but the funnel head intentionally uses a narrower feature subset and its own intercept/weights so funnel-specific dynamics can be tuned without destabilizing general risk detection.

Before inference, the scorer builds a rich context for each incoming message. It combines the parsed message, behavior analysis results, intent tags, per-player message timing, funnel progression state, and a histogram of already triggered upstream signals. This means the model sees more than text: it also sees interaction tempo, channel type, intent progression, and how much independent evidence has already been accumulated by other stages.

Dense features are extracted from that context in a fixed feature space. They include lexical indicators (payment/account/urgency/trust/platform words), structural cues (links or suspicious punctuation), behavior flags (upfront payment pressure, sensitive-data requests, repeated contact, spam-like pressure), intent flags (offer/rep/redirect/instruction/payment/anchor), channel flags, normalized signal-hit counters, and normalized funnel progression indicators such as funnel step index, sequence strength, and full/partial chain markers.

On top of dense features, the main head also consumes token features derived from message n-grams. The tokenizer normalizes text into word-like tokens and generates contiguous n-grams (2 to 5 words). During inference, the model sums the configured token weights for any n-grams present in the current message, which allows local lexical adaptation without changing the dense feature schema.

The final inference step is straightforward: linear combination, sigmoid probability, then threshold gating. In other words, intercept plus weighted dense features plus weighted token features are passed through a sigmoid; probability is converted into a capped score, but that score is only emitted if probability passes the configured trigger threshold. If not triggered, the stage returns no AI score for that head.

The funnel head follows the same pattern but is evaluated only when funnel context is meaningful, for example when a full or partial funnel chain is active, when funnel progression has reached deeper steps, or when explicit funnel-stage hits already exist. Its trigger threshold is derived from the base AI threshold plus a configurable funnel bonus, and its maximum score is independently bounded so funnel emphasis can be increased or limited safely.

When a head triggers, the stage emits an AI signal with source `AI`, an explicit rule id (`LOCAL_AI_RISK_SIGNAL` or `LOCAL_AI_FUNNEL_SIGNAL`), the computed score, and an evidence string containing probability, threshold, and top contributing factors. Explanations are intentionally short and rank the strongest positive/negative contributors so developers and moderators can debug behavior without reverse-engineering the full weight table.

Model persistence is file-based. The local model config stores schema version, intercept, dense feature weights, token weights, and a dedicated funnel head block. On load, the config is normalized to the current schema: missing defaults are backfilled, unsupported/missing funnel fields are repaired, and both heads are guaranteed to have valid feature maps. This keeps older model files forward-compatible with new client versions.

Model distribution is handled by an update service that checks a remote version manifest, compares local version/hash, downloads pending updates, verifies payload integrity, and then offers explicit actions: accept, merge, or ignore. Accept replaces the local model after creating a backup; merge keeps remote values while filling missing entries from local weights so custom local tuning is not silently lost.

The training loop is human-in-the-loop and data-centric. The client can capture chat lines, attach labels, and append structured rows to a training CSV that already includes intent, funnel, behavior, and signal-hit metadata plus sample weighting hints. A local helper prepares and archives normalized upload files, while community retraining and new weight generation happen outside the client. In short: the client performs inference and data collection locally, while full model fitting is externalized.

Operationally, the best way to tune AI behavior is to treat it as a calibrated layer on top of deterministic evidence. Start with threshold and max-score settings, then adjust dense/funnel weights, and only then touch token weights for lexical refinement. If outputs look unstable, inspect context quality first: malformed channels, missing upstream signals, broken intent tagging, or stale funnel state will usually degrade AI quality more than model weights themselves.
